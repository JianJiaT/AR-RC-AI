# CG4002 B04 AI Code
## Overview
The code here implements both the software and hardware parts of the AI model for our project, which was deployed on an Ultra96-V2 board and used for gesture detection and classification on sensor data

## Python Code
**`data_splitter.ipynb`**: Splits collected data into smaller, 50-datapoint windows and indexes them in `.csv` label files  
**`NN.ipynb`**: The core of the software AI implementation. Creates datasets and dataloaders from the label files, creates test files for use later on in the pipeline, trains and evaluates the model on the test set, and saves model parameters

## Vitis Code
C++ Code intended for use in Vitis HLS to generate an IP block that implements our AI model. **`nn_tester.cpp`** is used to ensure that the model's parameters and algorithms have been correctly ported over from Python

## Vivado
Contains the Vivado project where our IP block is integrated with the rest of the Ultra96. Can be used to view the various aspects of the hardware implementation, such as the block design and timing, power and resource utilization reports. The **`hardware_NN`** zip file and folder are generated by Vitis

## Ultra96 Code
Code run on the Ultra96 to make gesture classifications on sensor data. **`hardware_ai.py`** contains the PYNQ code necessary to set up and send data to and from the hardware, which is encapsulated in a class that provides logging and data processing utilities. **`design_1_wrapper.xsa`** is generated by Vivado